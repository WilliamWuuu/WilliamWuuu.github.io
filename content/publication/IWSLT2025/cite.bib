@inproceedings{wei-etal-2025-hitszs,
    title = "{HITSZ}{'}s End-To-End Speech Translation Systems Combining Sequence-to-Sequence Auto Speech Recognition Model and {I}ndic Large Language Model for {IWSLT} 2025 in {I}ndic Track",
    author = "Wei, Xuchen  and
              Wu, Yangxin  and
              Zhang, Yaoyin  and
              Liu, Henglyu  and
              Chen, Kehai  and
              Bai, Xuefeng  and
              Zhang, Min",
    editor = "Salesky, Elizabeth  and
              Federico, Marcello  and
              Anastasopoulos, Antonis",
    booktitle = "Proceedings of the 22nd International Conference on Spoken Language Translation (IWSLT 2025)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria (in-person and online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.iwslt-1.43/",
    pages = "405--411",
    ISBN = "979-8-89176-272-5",
    abstract = "This paper presents HITSZ{'}s submission for the IWSLT 2025 Indic track, focusing on speech-to-text translation (ST) for English-to-Indic and Indic-to-English language pairs. To enhance translation quality in this low-resource scenario, we propose an end-to-end system integrating the pre-trained Whisper automated speech recognition (ASR) model with Krutrim, an Indic-specialized large language model (LLM). Experimental results demonstrate that our end-to-end system achieved average BLEU scores of 28.88 for English-to-Indic directions and 27.86 for Indic-to-English directions. Furthermore, we investigated the Chain-of-Thought (CoT) method. While this method showed potential for significant translation quality improvements on successfully parsed outputs (e.g. a 13.84 BLEU increase for Tamil-to-English), we observed challenges in ensuring the model consistently adheres to the required CoT output format."
}
